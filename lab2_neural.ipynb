{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shashwatsaket46/study/blob/main/lab2_neural.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Acknowledgement\n",
        "\n",
        "This lab is imported from prof. Christopher Musco's 2024 iteration of CS-GY 6923. Thanks Chris!"
      ],
      "metadata": {
        "id": "utIsaFjEC65A"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_tllo2lWCrzt"
      },
      "source": [
        "# Lab:  Model Order Selection for Neural Data\n",
        "\n",
        "Machine learning is a key tool for neuroscientists to understand how sensory and motor signals are encoded in the brain.  In addition to improving our scientific understanding of neural phenomena, understanding neural encoding is critical for brain machine interfaces (see. e.g. https://www.youtube.com/watch?v=QRt8QCx3BCo).  In this lab, you will use model selection for performing some simple analysis on real neural signals.  \n",
        "\n",
        "Before doing this lab, you should review the ideas in the polynomial model selection demo.  In addition to the concepts in that demo, you will learn to:\n",
        "* Represent neural time-series data in arrays\n",
        "* Load data from a pickle file\n",
        "* Describe and fit memoryless linear models\n",
        "* Describe and fit linear time-series models with delays\n",
        "* Fit linear models with multiple target outputs\n",
        "* Select the optimal delay via cross-validation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A7FQzeSQCrzv"
      },
      "source": [
        "## Loading the data\n",
        "\n",
        "The data in this lab comes from neural recordings described in:\n",
        "\n",
        "<a href=\"https://pubmed.ncbi.nlm.nih.gov/21613593/\">\n",
        "Stevenson, Ian H., et al. \"Statistical assessment of the stability of neural movement representations.\" Journal of neurophysiology 106.2 (2011): 764-774</a>\n",
        "\n",
        "Neurons are the basic information processing units in the brain.  Neurons communicate with one another via *spikes* or *action potentials* which are brief events where voltage in the neuron rapidly rises then falls.  These spikes trigger the electro-chemical signals between one neuron and another.  In this experiment, the spikes were recorded from 196 neurons in the primary motor cortex (M1) of a monkey using an electrode array implanted onto the surface of a monkey's brain.  During the recording, the monkey performed several reaching tasks and the position and velocity of the hand was recorded as well.  \n",
        "\n",
        "The goal of the experiment is to try to *read the monkey's brain*:  That is, predict the hand motion from the neural signals from the motor cortex. Being able to make such predictions is the precursor to [technologies like Braingate and Neuralink](https://www.youtube.com/watch?v=QRt8QCx3BCo) that use electrode implants to read neural activity that then controls a cursor or robotic arm.\n",
        "\n",
        "We first load the key packages."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "jQZdRK_ECrzw"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import r2_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mM-ENp65Crzx"
      },
      "source": [
        "The full data is available on the CRCNS website  http://crcns.org/data-sets/movements/dream.  This website has a large number of datasets and can be used for projects as well.  However, the raw data files can be quite large.  To make the lab easier, the [Kording lab](http://kordinglab.com/) at UPenn has put together an excellent [repository](https://github.com/KordingLab/Neural_Decoding) where they have created simple pre-processed versions of the data.  You can download the file `example_data_s1.pickle` from [this link](https://github.com/cpmusco/machinelearning2022/blob/master/data/example_data_s1.pickle?raw=true).  Alternatively, you can directly run the following code."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "6ILHrj-mCrzx"
      },
      "outputs": [],
      "source": [
        "fn_src = 'https://github.com/cpmusco/machinelearning2022/blob/master/data/example_data_s1.pickle?raw=true'\n",
        "fn_dst = 'example_data_s1.pickle'\n",
        "\n",
        "import os\n",
        "from six.moves import urllib\n",
        "\n",
        "if os.path.isfile(fn_dst):\n",
        "    print('File %s is already downloaded' % fn_dst)\n",
        "else:\n",
        "    urllib.request.urlretrieve(fn_src, fn_dst)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B0PFYQ79Crzy"
      },
      "source": [
        "The file is a *pickle* data structure, which is a package to serialize python objects into data files.  Once you have downloaded the file, you can run the following command to retrieve the data from the pickle file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "M5j--2KbCrzy"
      },
      "outputs": [],
      "source": [
        "with open('example_data_s1.pickle', 'rb') as fp:\n",
        "    X,y = pickle.load(fp)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EsuoKB-wCrzz"
      },
      "source": [
        "The matrix `X` is matrix of spike counts where `X[i,j]` is the number of spikes from neuron `j` in time bin `i`.\n",
        "The matrix `y` has two columns:\n",
        "* `y[i,0] = ` velocity of the monkey's hand in the x-direction\n",
        "* `y[i,1] = ` velocity of the monkey's hand in the y-direction\n",
        "\n",
        "Our goal will be to predict **only** `y[i,0]` from `X`. We could just as easily predict movement in both directions, but this simplifies the lab.  So we reassign:"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pYhriuG8OFN0"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "v3DEsangCrzz",
        "outputId": "9f4bd8e6-c1b1-4730-fd8f-0d6a3d96d4f6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 1.51037413e-01, -1.39498351e-01, -3.55773944e-01, ...,\n",
              "        3.19722904e-06,  7.24814520e-07,  9.51148351e-07])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "y = y[:,0]\n",
        "y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1-JH7bgMCrz0"
      },
      "source": [
        "Each time bin represent `tsamp=0.05` seconds of time.  Using `X.shape` and `y.shape` compute and print:\n",
        "* `nt = ` the total number of time bins\n",
        "* `nneuron = ` the total number of neurons\n",
        "* `ttotal = ` total time of the experiment is seconds."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "metadata": {
        "id": "0ngUEh6TW1jN",
        "outputId": "0129df8b-d823-496d-b98a-737d913db31d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(61339, 52)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "-_U3-5s4Crz1"
      },
      "outputs": [],
      "source": [
        "tsamp = 0.05  # sampling time in seconds\n",
        "\n",
        "nt = X.shape[0]\n",
        "nneuron = X.shape[1]\n",
        "ttotal = nt * tsamp"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "So, here the X.shape will have two componsents. The first would be total number of time bins which is 61339 as time bin is denoted by i, and other component would be total number of neurons which is 52 as neuron is denoted by j."
      ],
      "metadata": {
        "id": "HbgNMbELWu-i"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_2dukHJNCrz1"
      },
      "source": [
        "## Fitting a Memoryless Linear Model\n",
        "\n",
        "Let's first try a simple linear regression model to fit the data.\n",
        "\n",
        "Before doing so, we want to split the data into a training and test set. We will use a 2/3 - 1/3 split, so 1/3 of the data should be used for testing.\n",
        "\n",
        "Let `Xtr,ytr` be the training data set and `Xts,yts` be the test data set. Recall that `ytr` and `yts` should be taken from the *first column of `y` only*. You can use any utility to perform the split that you want, but make sure that it is *random*. I.e. don't just take the first rows of the data to be the training data. `np.random.permutation` might come in handy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "1kazgWggCrz2"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "Xtr, Xts, ytr, yts = train_test_split(\n",
        "    X, y, test_size=1/3, random_state=0, shuffle=True\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here I am using the sklearn library train_test_split, keeping the test_size as 1/3 will ensure 2/3, 1/3 data split. Also to reproduce, I am using a seed, and I am shuffling the data to remove any bias."
      ],
      "metadata": {
        "id": "MD90Gq88YzSG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, write an function that, fits a linear model given a predictor matrix X and a vector of target values y. Your function should find the optimal beta to minimize the squared loss. You should do so using the matrix equations discussed in class -- do not use any built in functions from e.g. Scikit Learn.\n",
        "\n",
        " Your linear model should have an intercept (a column of all oness). Hint: You might want to use numpy's concatenate function and the ones function."
      ],
      "metadata": {
        "id": "TtmylUtz1Ued"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def fit_mult_linear(X,y):\n",
        "    \"\"\"\n",
        "    Given matrix of predictors X and target vector y fit for a multiple linear regression model under the squared loss.\n",
        "    \"\"\"\n",
        "    # TODO complete the following code\n",
        "    # beta = ...\n",
        "    return beta"
      ],
      "metadata": {
        "id": "aiWfh_Bj1iAz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1twTYs0eCrz2"
      },
      "source": [
        "Now, use your function to fit a multiple linear regression model under squared loss using `Xtr,ytr`.\n",
        "Make predictions  `yhat` using `Xts`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5hTviMf1Crz2"
      },
      "outputs": [],
      "source": [
        "# TODO\n",
        "# yhat = ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TqgNOrM9Crz2"
      },
      "source": [
        "Compare `yhat` to `yts` to measure the **averaged squared loss** (empirical risk) on the test set. Print the output. You should obtain an average loss of around 32 or 33 if you are normalizing by 1/(test set size)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OEF3B3JFCrz3"
      },
      "outputs": [],
      "source": [
        "# TODO\n",
        "# loss ="
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IHn0sLXlCrz3"
      },
      "source": [
        "It is useful to plot the predicted vs. true values. Plot `yhat` vs. `yts` with a scatter plot and label the axes. If the predicted values exactly matched the targets, we would expect to see a line with slope 1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RtwkJAruCrz3"
      },
      "outputs": [],
      "source": [
        "# TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y2Fyog-iCrz4"
      },
      "source": [
        "## Fitting Models with Delay\n",
        "\n",
        "One way we can improve the model accuracy is to used delayed version of the features.  Specifically, the model we used above mapped the features\n",
        "\n",
        "$$\n",
        "\\hat{y}_i = \\sum_{j=1}^{p} X_{i,j}*\\beta_j + \\beta_0\n",
        "$$\n",
        "where $p$ is the number of features and $\\beta$ is our vector of coefficients.  In this model,  $\\hat{y}_i$ at time $i$ was only dependent on the inputs  $X_{i,1,\\ldots,p}$ at time $i$.  In signal processing, this is called a *memoryless* model.  However, in many physical systems, such as those that arise in neuroscience, there is a delay between the inputs $X_{i,1,\\ldots,p}$ and the outputs $y_i$.  For such cases, we can use a model of the form,\n",
        "\n",
        "$$\n",
        "\\hat{y}_{i+d} = \\sum_{m=0}^d \\sum_{j=1}^{p} X_{i+m,j}*\\beta_{j,m} + \\beta_{0,m}\n",
        "$$\n",
        "    \n",
        "where $\\beta$ is now a 2-dim array of coefficients where $\\beta_{j,m}$ is the influence of the input $X_{i+m,j}$ onto output $y_{i+d}$\n",
        "\n",
        "\n",
        "In signal processing, this model is called an *FIR* filter.  The point is that the output at time `i+d` depends on the inputs at times `i,i+1,...,i+d`.  Hence, it depends on the last `d+1` time steps, not just the most recent time.\n",
        "\n",
        "To translate this into a linear regression problem, complete the following function that creates a new feature and target matrix where:\n",
        "\n",
        "    Xdly[i,:] is the concatenation of the vectors X[i,:], X[i+1,:], ..., X[i+d,:]\n",
        "    ydly[i,:] = y[i+d,:]\n",
        "    \n",
        "Note that if `X` is `n x p` then `Xdly` will be `n-d x (d+1)*p`.  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YQ20N8P0Crz4"
      },
      "outputs": [],
      "source": [
        "def create_dly_data(X,y,d):\n",
        "    \"\"\"\n",
        "    Create delayed data\n",
        "    \"\"\"\n",
        "    # TODO\n",
        "    # Xdly = ...\n",
        "    # ydly = ...\n",
        "\n",
        "    return Xdly, ydly\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OTzKnLsQCrz4"
      },
      "source": [
        "Now fit an linear delayed model with `d=6` additional delay lags.  That is,\n",
        "* Create delayed data `Xdly,ydly=create_dly_data(X,y,6)`\n",
        "* Split the data into training and test as before\n",
        "* Fit the model on the training data\n",
        "* Measure the average squared loss (risk) on the test data\n",
        "\n",
        "You should see a significant improvement from the memoryless model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f9bhJ1m_Crz4"
      },
      "outputs": [],
      "source": [
        "# TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2NH12ZLuCrz5"
      },
      "source": [
        "Plot the predicted vs. true values as before. You should visually see the improvement too."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y8_1L9aICrz5"
      },
      "outputs": [],
      "source": [
        "# TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zpntYh3RCrz5"
      },
      "source": [
        "## Selecting the Optimal Delay via Model Order Selection\n",
        "\n",
        "In the previous example, we fixed `d=6`.  We can now select the optimal delay using model order selection.  Since we have a large number of data samples, it turns out that the optimal model order uses a very high delay.  \n",
        "So to save on computation time, we will just do a simple train-test split. We won't do any k-fold cross-validation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Ob5LUgtCrz5"
      },
      "source": [
        "We will look at model orders up to `dmax=30`.  Create a delayed dataset, `Xdly,ydly` using `create_dly_data` with `dly=dmax`. Split this data into training and test data as before, with a 2/3 -1/3 split."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mhRgMEFFCrz5"
      },
      "outputs": [],
      "source": [
        "dmax = 30\n",
        "\n",
        "# TODO\n",
        "# Xdly, ydly = ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cdDankI2Crz6"
      },
      "source": [
        "Implement a loop to test different amounts of delay from 0 to `dmax`. For each delay, you should train on the train set and compute the average squared loss on the test set. Store these losses in an array `losses`.\n",
        "\n",
        "**Important Note**: for different delay values you should be using a different **subset of columns** from the `Xdly` matrix you just created. To save time, you don't want to be re-creating a new test set for each model order you experiment with.\n",
        "\n",
        "Your code could take a long time (several minutes) to run! This is a large data set and we are using many features in our multivariate regression. You might want to test/debug your code with a signficantly small value of `dmax` before doing a final run."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6-bbWPoDCrz6"
      },
      "outputs": [],
      "source": [
        "# losses = np.zeros(dmax)\n",
        "# for i in range(0,dmax):\n",
        "    # TODO\n",
        "    # losses[i] ="
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kx1-7un8Crz6"
      },
      "source": [
        "Which amount of delay lead to the best model fit? Plot losses as a function of `range(0,dmax)` to visualize how generalization of your model changes with increasing complexity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q2JWfPcTCrz6"
      },
      "outputs": [],
      "source": [
        "# TODO\n",
        "# best_delay="
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}